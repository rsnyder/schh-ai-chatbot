{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain RAG with chat history and streaming\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "We'll use the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-community langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load API keys into environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct retriever and populate vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import bs4\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "  web_paths=('https://lilianweng.github.io/posts/2023-06-23-agent/',),\n",
    "  bs_kwargs=dict(\n",
    "    parse_only=bs4.SoupStrainer(class_=('post-content', 'post-title', 'post-header'))\n",
    "  )\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Pinecone vector store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone\n",
    "\n",
    "model_name = 'text-embedding-ada-002'  \n",
    "index_name = 'schh'\n",
    "text_field = 'text'\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "index = pc.Index(index_name)\n",
    "embeddings = OpenAIEmbeddings( model=model_name, openai_api_key=os.getenv('OPENAPI_API_KEY') )\n",
    "vectorstore = PineconeVectorStore( index, embeddings, text_field )  \n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contextualize question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "contextualize_q_system_prompt = '''Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.'''\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder('chat_history'),\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "system_prompt = '''You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}'''\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    ('system', system_prompt),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('human', '{input}'),\n",
    "  ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statefully manage chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key='input',\n",
    "    history_messages_key='chat_history',\n",
    "    output_messages_key='answer',\n",
    ").with_config(tags=['main_chain'])\n",
    "\n",
    "def print_response(resp):\n",
    "  as_dict = {\n",
    "    'input': resp['input'],\n",
    "    'chat_history': [doc.model_dump() for doc in resp['chat_history']],\n",
    "    'context': [doc.model_dump() for doc in resp['context']],\n",
    "    'answer': resp['answer']\n",
    "  }\n",
    "  print(json.dumps(as_dict, indent=2) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessageChunk\n",
    "\n",
    "async def generate_chat_events(message, session_id):\n",
    "  \n",
    "  def serialize_aimessagechunk(chunk):\n",
    "    if isinstance(chunk, AIMessageChunk):\n",
    "      return chunk.content\n",
    "    else:\n",
    "      raise TypeError(f'Object of type {type(chunk).__name__} is not correctly formatted for serialization')\n",
    "  \n",
    "  try:\n",
    "    async for event in conversational_rag_chain.astream_events(message, version='v1', config={'configurable': {'session_id': session_id}} ):\n",
    "      # print(event['tags'], event['event'], event.get('data',{}).get('chunk'))\n",
    "      # Only get the answer\n",
    "      sources_tags = ['seq:step:3', 'main_chain']\n",
    "      if all(value in event['tags'] for value in sources_tags) and event['event'] == 'on_chat_model_stream':\n",
    "        chunk_content = serialize_aimessagechunk(event['data']['chunk'])\n",
    "        if len(chunk_content) != 0:\n",
    "          yield chunk_content\n",
    "          \n",
    "  except Exception as e:\n",
    "    print('error'+ str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"input\": \"tell me about the golf plans\",\n",
      "  \"chat_history\": [],\n",
      "  \"context\": [\n",
      "    {\n",
      "      \"id\": \"f463964dc775b88e7db54b29d7dbe86d286f1c35613b2cea2492105d8d690a32\",\n",
      "      \"metadata\": {},\n",
      "      \"page_content\": \"of class changes may result in a fee.\\nFitness instruction on all Association property shall be taught by Sun City Hilton Head Community Association staff \\nand/or approved contractors only. \\nPersons with known medical problems or who are unsure of their physical condition are strongly advised to consult \\nwith their physician(s) before engaging in exercise activity.\\n5.9. Gazebos/Shade Structures \\nThe gazebos are available for use on a first come, first served basis, located near the tennis courts at the Barataria \\noutdoor pool deck and at Lake Somerset. All shade structures are available on a first come, first served basis.  \\n5.10. Golf Courses \\nLocations\\n\\u2022 Hidden Cypress\\n\\u2022 Okatie Creek\\n\\u2022 Argent Lakes \\nOnly residents and their invited guests may play the courses. There is no public access. Reservations can\\nbe made through Chelsea Reservation System on the community website at www.SunCityHiltonHead.org . Same\",\n",
      "      \"type\": \"Document\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"fd5ad11a8221523b4b1f369f748bcc5f79e7104e391da8fd41f559ffcdb2506e\",\n",
      "      \"metadata\": {},\n",
      "      \"page_content\": \"one time can be used for a 30-day stay for maximum of three months. Campers must enter and make payment \\nat the Main Gate south of Hwy. 278 upon arrival. If arrival is after 6 p.m., arrangements will be made for payment. \\nGuests will be shown to their campsite as needed. Checkout time is 11 a.m. Pets are welcome but must be kept on a \\nleash and owners must pick up after them.\\n5.3. Bocce Courts\\nThe bocce courts are located in Town Square. Court usage is on a first come, first served basis during open times \\nwhen the club is not using the facility. See SunSations magazine for club information regarding group play and \\nspecial events. Residents may borrow loaner equipment located in the storage box near the bocce courts. Reserva -\\ntions can be made through Chelsea Reservation System on the community website at www.SunCityHiltonHead.\\norg.    \\n5.4. Children\\u2019s Playground\\nThe Children\\u2019s Playground is available during daylight hours only. Children shall be monitored at all times by a\",\n",
      "      \"type\": \"Document\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"d1ab1925f21201cfc94b639bf2b03f9aa1ab9018f43f84ff4ffe9c4df357c111\",\n",
      "      \"metadata\": {},\n",
      "      \"page_content\": \"or nanny suite, but not for independent leasing. There shall be no subleasing of dwelling units or assignment of \\nleases unless prior written approval is obtained from the Board. All leases shall be in writing. No transient tenants \\nmay be accommodated in a dwelling unit, and all leases shall be for an initial term of no less than 90 days. The \\nleasing of any lot is further subject to the restrictions on occupancy set forth in Section 2.3 of the Declaration. The \\nhomeowner is ultimately responsible for informing the Community Association of lease expiration date for the \\nresidence.\\nCommunity Rules 2025\",\n",
      "      \"type\": \"Document\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"5652bcda3b105f6debb9a783af6fc2c02be4423e3a24479b14ba1e744204a1b3\",\n",
      "      \"metadata\": {},\n",
      "      \"page_content\": \"org.    \\n5.4. Children\\u2019s Playground\\nThe Children\\u2019s Playground is available during daylight hours only. Children shall be monitored at all times by a \\nresponsible adult and shall not be left unattended in the playground area.  \\n5.5. Croquet Lawns\\nThe croquet lawns are located in Town Square. Usage is on a first come, first served basis during open times when \\nthe club is not using this facility. SunSations magazine lists club times under the Croquet Club listing in the Char -\\ntered Club News section of each issue. \\n         \\nCommunity Rules 2025\",\n",
      "      \"type\": \"Document\"\n",
      "    }\n",
      "  ],\n",
      "  \"answer\": \"The golf courses at Sun City Hilton Head, including Hidden Cypress, Okatie Creek, and Argent Lakes, are accessible only to residents and their invited guests, with no public access. Reservations for tee times can be made through the Chelsea Reservation System on the community's website.\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The golf courses at Sun City Hilton Head, including Hidden Cypress, Okatie Creek, and Argent Lakes, are accessible only to residents and their invited guests, with no public access. Reservations for tee times can be made through the Chelsea Reservation System on the community's website.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_1 = 'tell me about the golf plans'\n",
    "sessionid = 'abc123'\n",
    "\n",
    "resp = conversational_rag_chain.invoke(\n",
    "    {'input': prompt_1},\n",
    "    config={\n",
    "        'configurable': {'session_id': sessionid}\n",
    "    },\n",
    ")\n",
    "print_response(resp)\n",
    "resp['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, if an application is denied, homeowners can revise the application or appeal the decision by contacting the Modifications Coordinator listed in their denial letter for next steps.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_2 = 'Is there an appeal process for this?'\n",
    "\n",
    "conversational_rag_chain.invoke(\n",
    "    {'input': prompt_2},\n",
    "    config={'configurable': {'session_id': sessionid}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage with streaming output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task\n",
      " decomposition\n",
      " is\n",
      " the\n",
      " process\n",
      " of\n",
      " breaking\n",
      " down\n",
      " a\n",
      " complex\n",
      " task\n",
      " into\n",
      " smaller\n",
      ",\n",
      " simpler\n",
      " steps\n",
      " to\n",
      " make\n",
      " it\n",
      " more\n",
      " manageable\n",
      ".\n",
      " This\n",
      " approach\n",
      " enhances\n",
      " model\n",
      " performance\n",
      " by\n",
      " allowing\n",
      " for\n",
      " structured\n",
      " reasoning\n",
      " and\n",
      " easier\n",
      " execution\n",
      " of\n",
      " tasks\n",
      ".\n",
      " Techniques\n",
      " such\n",
      " as\n",
      " Chain\n",
      " of\n",
      " Thought\n",
      " (\n",
      "Co\n",
      "T\n",
      ")\n",
      " and\n",
      " Tree\n",
      " of\n",
      " Thoughts\n",
      " are\n",
      " commonly\n",
      " used\n",
      " to\n",
      " facilitate\n",
      " this\n",
      " process\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "async for event in generate_chat_events({'input': prompt_1, 'chat_history': []}, sessionid):\n",
    "    print(event)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using with FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.responses import StreamingResponse, Response, FileResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from typing import Optional\n",
    "import secrets\n",
    "\n",
    "app = FastAPI()\n",
    "app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_credentials=True, allow_methods=['*'], allow_headers=['*'])\n",
    "\n",
    "@app.get('/')\n",
    "async def root():\n",
    "  return FileResponse('index.html')\n",
    "\n",
    "@app.get('/chat/{prompt}')\n",
    "async def chat(prompt: str, sessionid: Optional[str] = None, stream: Optional[bool] = False):\n",
    "    sessionid = sessionid or secrets.token_hex(4) # Generates 4 bytes, resulting in an 8-character hex string\n",
    "\n",
    "    if stream:\n",
    "        return StreamingResponse(generate_chat_events({'input': prompt, 'chat_history': []}, sessionid), media_type='text/event-stream')\n",
    "    else:\n",
    "        resp = conversational_rag_chain.invoke({'input': prompt}, config={'configurable': {'session_id': sessionid}}, )\n",
    "        # print(json.dumps(store[sessionid].model_dump(), indent=2))\n",
    "        # print_response(resp)\n",
    "        return Response(status_code=200, content=resp['answer'], media_type='text/plain')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
